\chapter{Problem Statement and Solver Methods}
\label{sec:solver}

In the following, the problem to optimize will be introduced an analyzed.
Although the thesis is not looking into finding the optimal solution, different solver strategies have to be introduced and compared to each other, as the utility function is not trivial and the differences are severe.
Their advantages and disadvantages will be shown.
If not specific mentioned, we will look at a 2x2 MIMO system with one receive antenna per user and three relays, as shown in Figure~\ref{fig:system2x23}.
The relays in this system will be lossless, i.e. the impedances will be pure imaginary.

\section{Utility Function}
\label{sec:utility_function}
As the aim for wireless communication networks is to maximize the achievable rate, we take the formulas derived in Section~\ref{sec:full_transf}, which describe the rates for each transmit-receive pair.
In order to get an utility function from the achievable rates, we stack them into the vector $\vec{r} = \begin{bmatrix}
r_1 \\ r_2 \\ \vdots \\ r_N
\end{bmatrix}$.

To optimize the rates, different approaches are possible.
\begin{itemize}
\item Optimize the minimum rate, i.e. $\text{max}\left(\text{min}(\vec{r})\right)$ (maxmin),
\item Optimize the mean rate, i.e. $\text{max}\left(\sum(\vec{r})\right)$ (maxsum), and
\item Optimize the maximum rate, i.e. $\text{max}\left(\text{max}(\vec{r})\right)$ (maxmax).
\end{itemize}

This is done using the LP-norm ($||\vec{r}||_p$)~\cite{wiki:lp_space}.
By setting $p = -\text{Inf}$, the "maxmin" method is achieved.
Setting $p = 1$, the "maxsum" method is applied and setting $p = +\text{Inf}$, the "maxmax" method is applied.
For all values in between, the utility function "tends" to optimize the maximum and minimum value respectively.

In the following we restrict ourselves to the "maxsum" method.
As the other methods easily can be applied and will lead to a similarly good result without loss of generality.

\subsection{Convexity of the Utility Function}
\label{sec:}

In the following the convexity of the utility function is analyzed.
This is done, because the choice of the solver depends on the shape of the utility function (e.g. in case of a concave utility function, a normal gradient search is sufficient to provide good results).

To do so, we analyze the utility function at different input values for the passive relays and at different input power values.
It is clear, that the function changes (heavily) for every channel realization.
Figure~\ref{fig:convex_3} shows two different channel realizations for the same input power and the same domain of two passive impedances.

\begin{figure}
\minipage{0.5\textwidth}
  \includegraphics[width=\linewidth]{images/convex_1.png}
  %\caption{A really Awesome Image}
   \label{fig:convex_1}
\endminipage%\hfill
\minipage{0.5\textwidth}
  \includegraphics[width=\linewidth]{images/convex_2.png}
  %\caption{A really Awesome Image}
   \label{fig:convex_2}
\endminipage\hfill
\caption{The utility function for different imaginary relay impedances for two relays and two different channel realizations.}
   \label{fig:convex_3}
\end{figure}


\subsection{Dependency on the Input Power}
\label{sec:}

We will analyze now the utility function for different input powers.
In Figure~\ref{fig:utility_power1} and Figure~\ref{fig:utility_power2} we see the same channel realization for two different input powers.
Figure~\ref{fig:utility_power3} shows again the same channel realization at an input power close to the input power of Figure~\ref{fig:utility_power2}.

First we observe, that the optima in Figure~\ref{fig:utility_power1} and Figure~\ref{fig:utility_power2} lie at very different impedance values of the relays, therefore we can conclude, that an optimal solution for one input power does not necessarily lead to a good solution for a different input power solution.

Next we analyze the optima of Figure~\ref{fig:utility_power3} and Figure~\ref{fig:utility_power2}.
Here we can see again, that using the values from Figure~\ref{fig:utility_power3} in Figure~\ref{fig:utility_power2} will not lead to the best solution, however it would serves as a good initial value for a gradient search method.


\subsection{Difference of Local Optima}
\label{sec:}

Last, we want to look at the local optima we can possibly run into.
We see in Figure~\ref{fig:utility_power1}, that if we hit the local optimum at the left, the performance will be nearly the same as with the local optimum at the right.
However looking at Figure~\ref{fig:utility_power2}, we see that the difference of the local optimum before the peak and the peak itself is severe.
Therefore, we can not only try to run the optimization with one initialization, but instead, we need multiple initializations.

\subsection{Complexity of the Problem}
\label{sec:}

As we will discuss different solver approaches in the following Sections, a short description of the complexity of the problem is given.
For each relay we use, we will have one variable ($N_\text{Rel}$), if we restrict the relays to the imaginary domain.
Allowing the relay to become lossy and therefore the impedance complex, the number of variables is doubled.% ($2\cdot N_\text{Rel}$).
Further for each receiver branch, i.e. receiver antenna, we have a reciprocal (lossless) matching network (see Section~\ref{sec:matching_network}), which has to be optimized.
Therefore we have three elements per branch (in total: $3\cdot N_\text{R}\cdot N_\text{Rx}$).
For a four user MIMO system with two receive antennas and five lossy relays per user, this would lead to a problem of size $N_\text{var} =  2\cdot 4\cdot 5 + 3\cdot 4\cdot 2 = 64$.
As mentioned in the beginning of this chapter, we look at a 2x2 MIMO system with one receive antenna and three lossless relays.
The complexity of this system is therefore $N_\text{var} =  1\cdot 2\cdot 3 + 3\cdot 2\cdot 1 = 12$.

\section{Gradient Search}
\label{sec:grads_solver}

Despite this large number of variables and the non-convexity of the utility function, the first approach remains a gradient search.
Figure~\ref{fig:grad_search} shows the typical behaviour of the gradient search for a realization over the iteration steps.
In the following, different methods are described, to improve the algorithm.

\begin{figure}
\centering
  \includegraphics[width=0.5\linewidth]{images/rvsgradCnt_7rel_18dB_6.png}
\caption{The sum rate over the gradient search iterations.}
\label{fig:grad_search}
\end{figure}


\subsection{Choice of Initial Values}
\label{sec:grads_ini}

We try to overcome the non-pleasant properties of the problem with a larger number of initial guesses, so that the gradient search approach tends more towards a grid search optimization method.
The gradient search routine itself is then used as a refinement step of the grid search.
%(c.f. \cite{Adjashvili2012})

\begin{figure}[hb]
\centering
  \includegraphics[width=0.6\linewidth]{images/Inicomparison_edited.png}
\caption{Comparison of the number of initial values used.}
\label{fig:ini_comp}
\end{figure}

Figure~\ref{fig:ini_comp} shows the empirical CDFs of the optimized sum rate, for different numbers of initializations.
The initial values were drawn uniformly at random for $Z_{\text{Rel}}[i]\in[-600,600] j , \quad\forall i\in[1,N_{\text{Rel}}]$.

It is obvious and clear to see, that the larger the number of initializations, the better the result.
However, even with 25 and 60 initializations, there improvement is still immense, which shows, that the number of initializations must be a lot larger than twice the input vector length.
A good tradeoff between a decent optimization and a comparable small runtime of the optimization is achieved by a choice of four times the input vector length.

\subsection{Adaptive Step Size}
\label{sec:grads_stepsize}

The performance of the gradient search routine is improved by the use of an adaptive step size.
For each calculated gradient, the step taken into the direction of the gradient is increased until the new rate value is smaller than the previous calculated value as shown in Figure~\ref{fig:stepsize}.
Therefore the number of time-expensive gradient calculations is reduced immense.

\begin{figure}[h]
\centering
  \includegraphics[width=0.5\linewidth]{images/stepsize_scheme.png}
\caption{Schematic of the adaptive step size algorithm.}
\label{fig:stepsize}
\end{figure}


\subsection{Conjugate Gradient}
\label{sec:grads_conjgrad}

\begin{figure}[h]
\centering
\includegraphics[width=0.3\linewidth]{images/conjugate_gradient_example.png}
\caption{A comparison of the convergence of gradient descent with optimal step size (in green) and conjugate vector (in red) for minimizing a quadratic function associated with a given linear system\cite{wiki:conj_grad}.}
\label{fig:conj_grad_ex}
\end{figure}
As the gradient search performance still requires too many iterations, further improvements were made.
The shape of such complex problems can - in some cases - have the shape of a crest, where, with a unpleasant choice of the initial value, a pure gradient search routine might jump around the optimum, without improving a lot.
Conjugate gradient routines like "Fletcher-Reeves" or "Polak-Ribi\`{e}re" lead to a faster convergence, as they weight the gradient by the previous gradient and a weigth factor $\beta$. 

Like Polak-Ribi\`{e}re, the Fletcher-Reeves method updates the conjugate direction according to 
\begin{equation}
\vec{s}_n = \vec{g}_n + \beta_n\cdot\vec{g}_{n-1},
\label{eq:conj_update}
\end{equation}
where $\vec{g}$ denotes the gradient.
The conjugate direction $\vec{s}$ is then used to perform the conjugate gradient search.
Polak-Ribi\`{e}re and Fletcher-Reeves differ in the way, they calculate the weight factor $\beta$.

\subsubsection{Fletcher-Reeves}
For the method of Fletcher-Reeves, $\beta$ is calculated according to~\cite{Fletcher64}
\begin{equation}
\beta_n^{FR} = \frac{\vec{g}_n^T \vec{g}_n}{\vec{g}_{n-1}^T \vec{g}_{n-1}}.
\label{eq:beta_fr}
\end{equation}

\subsubsection{Polak-Ribi\`{e}re}
For the method of Polak-Ribi\`{e}re, $\beta$ is calculated according to~\cite{Polak69}
\begin{equation}
\beta_n^{PR} = \frac{\vec{g}_n^T\left(\vec{g}_n-\vec{g}_{n-1}\right)}{\vec{g}_{n-1}^T \vec{g}_{n-1}}.
\label{eq:beta_fr}
\end{equation}

In Figure~\ref{fig:pr_fr_sa} the pure gradient search (steepest ascent) method is compared to the methods of Fletcher Reeves and Polak-Ribi\`{e}re.
The Figure shows once the optimization after 50 iterations (solid lines), to see, which method optimizes the problem the best after just a few steps, and at 500 iterations, to see which routine might get caught in the shape  of the problem.
\begin{figure}[h]
\centering
  \includegraphics[width=0.9\linewidth]{images/Conjgradcomparison_edited.png}
\caption{Comparison between Steepest Ascent, Polak-Ribi\`{e}re, and Fletcher-Reeves.}
\label{fig:pr_fr_sa}
\end{figure}

We can see, that Fletcher-Reeves is not well suited for our kind of optimization problem.
Better is Polak-Ribi\`{e}re, which outperforms the standard gradient search method at 50 iterations and has a slightly better performance at 500 iterations.


\section{Heuristic Optimization Algorithms}
\label{sec:heuristic}

Due to the non convexity and the non trivial optimization problem, we further analyze (some) heuristic optimization methods.
In the following three heuristic algorithms will be introduced and analyzed by their performance.
They were chosen, because they already exist in the MATLAB library and do not require any strenuous implementation.

\subsection{Simulated Annealing}
\label{sec:sim_annealing}

Simulated Annealing was developed, as there is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters)~\cite{Kirkpatrick83}.
% This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods. 
In this thesis, Simulated Annealing was chosen as it is a method to solve optimization problems of multivariate optimization.

The Algorithm used in this thesis is a build-in function of MATLAB\copyright.
A description can be found on the MathWorks homepage~\cite{matlab:simulann}.

\begin{figure}[h]
\centering
  \includegraphics[width=0.9\linewidth]{images/Simannealcomparison.png}
\caption{Comparison of the Simulated Annealing algorithm for different number of initializations and the results from "Polak-Ribi\`{e}re" and "Steepest Ascent" gradient searches.}
\label{fig:heur_sa}
\end{figure}

Figure~\ref{fig:heur_sa} shows the performance of Simulated Annealing algorithm dependent on the choice of numbers of initializations (red curves).
Again we see, that the more initializations we have, the better the sum rate can be optimized.
However, we also see, that even with 60 initializations, Simulated Annealing leads to a result, which is worse than the sum rates achieved by steepest ascend (black dashed curve) and Polak-Ribi\`{e}re (blue dashed curve).


\subsection{GlobalSearch}
\label{sec:globals}

The other two heuristic optimization algorithms are GlobalSearch (GS) and MultiStart (MS).
They are very similar to each other, the only difference is the choice of the starting values.
As MultiStart requires the number of initialization values, GlobalSearch generates trial points on its own~\cite{matlab:gloabls}.
GlobalSearch - the optimization function, which we will analyze - is based on the MATLAB\copyright  built-in function \textit{fmincon}.
Figure~\ref{fig:globals_scheme} shows the schematics of GS and MS.
\begin{figure}[h]
\centering
  \includegraphics[width=0.7\linewidth]{images/global_algorithm.png}
\caption{Schematics of the GlobalSearch and MultiStart algorithms~\cite{matlab:gloabls}.}
\label{fig:globals_scheme}
\end{figure}

Figure~\ref{fig:globals} shows the performance of GlobalSearch (red curve).
We see, that it has almost the same performance as the conjugate gradient method by Polak-Ribi\`{e}re with 60 initializations (blue curve).
GlobalSearch is less dependent on the initial value - for the relays it is chosen very large ($\vec{X}_{\text{Rel}} = 1000j$) and not at random, compared to the gradient search methods, to simulate an open circuited antenna and therefore no coupling.

\begin{figure}[h]
\centering
  \includegraphics[width=0.8\linewidth]{images/Globalscomparison_edited.png}
\caption{Performance of the GlobalSearch algorithm in comparison to the previous results.}
\label{fig:globals}
\end{figure}

\section{Further Algorithm Improvements}

\subsection{Optimization of the Interference Function}

A further approach to optimize the gradient search routine is a good initial guess.
The problem of the sum rate maximization is reduced only to the description of the interference.
Therefore the number of variables can be reduced by a factor of two third for the matching network, as the interference function

REFERENCE

only requires the input impedance of the matching network.
This reduced problem has size of $N_\text{var} =  2\cdot N_\text{Rel}+2\cdot N_\text{R}\cdot N_\text{Rx} = 2\cdot 4\cdot 5 + 2\cdot 4\cdot 2 = 56$, for the same settings as above.
The factor 2 from the matching network variables comes from the fact, that with pure imaginary elements in the matching network, any complex value of the input impedance can be achieved.

\begin{figure}[h]
\centering
  \includegraphics[width=0.8\linewidth]{images/Inioptcomparison_edited.png}
\caption{Comparison of the number of initial values used.}
\label{fig:ini_comp}
\end{figure}

Figure~\ref{fig:globals} shows the performance of the steepest ascent algorithm, with the pre-optimized initial values (red curves).
We see, that using the five best pre-optimizations leads to a performance almost as good as initializing the algorithm with 60 random vectors (blues curve).
To push the optimization even further, we can combine these two techniques and take the best optimization from the five best pre-optimized initial values and 55 random initial values (black curve).
This leads to a $0.5 \left[\text{b/s/Hz}\right]$ improvement at the mean and a $1.5 \left[\text{b/s/Hz}\right]$ improvement for the lowest 10\% of the rates, than only considering random values.



\subsection{Post Refinement of GlobalSearch by Gradient Search}
Stepwise improvement of the relays.


\subsection{Stepwise Relay Improvements}
Stepwise improvement of the relays.







